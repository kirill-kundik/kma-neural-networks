{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6gse_7QJ0Nt",
        "outputId": "dc7f86c5-29f6-4b88-eab4-c3defb9a37a6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision \n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2F0NdOuMRSs"
      },
      "source": [
        "# Homework description\n",
        " \n",
        "In this homework, you have to build an image classification model that treats each image as a sequence of sub-images. Very similar to the recent architecture of [Visual Transformer](https://arxiv.org/pdf/2010.11929.pdf). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "eeb64292f3dd4eedac9267f0fdc329d8",
            "f69b49ac301f401b9e4ea65e175b7c3d",
            "8ac198372fcf4d0488a2aa66a004d226",
            "4e29e052a90945ed94a1a5be05d761ff",
            "0b790a4fd65b40f8948b7a4f5a168b71",
            "954e603782664638bd664b65844bb92b",
            "803460057842448bb386941dac2fd38d",
            "2496271792f2419fa86bbb1451f4b321",
            "b7b766da11a74875b9c95ce4b559c50f",
            "3b579581cf8d424dbb5e97181a277cf9",
            "114d5e5b363a4a10bdd8c6f624f0a317"
          ]
        },
        "id": "PnItCOvQJ0OL",
        "outputId": "1a1a544b-aaca-49bb-f0b0-cf2621fba343"
      },
      "outputs": [],
      "source": [
        "# Here we define our dataset and resize each image to (224, 224).\n",
        "# Consider adding your own data augmentations, like flip, blur, etc.\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [\n",
        "        torchvision.transforms.Resize((224, 224)),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = torchvision.datasets.Caltech256('data/', download=True, transform=transform)\n",
        "\n",
        "#################\n",
        "\n",
        "# YOUR CODE HERE\n",
        "# 1) Split the original dataset into the train, validation, and test datasets. \n",
        "# 2) Explain your choice of dataset sizes\n",
        "# 3) Create a dataloader for each dataset\n",
        "\n",
        "#################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly_ixW-uJ0OM"
      },
      "outputs": [],
      "source": [
        "# You can check how PatchEmbeddings class splits the image into patches using the image_to_patches function\n",
        "\n",
        "class PatchEmbeddings(torch.nn.Module):\n",
        "    def __init__(self, patch_size, d_model, channels=3):\n",
        "        ''' Patch Embedding class. \n",
        "                Takes image as an input, splits it into a number of patches of the pre-determined size (patch_size) \n",
        "                and applies a linear transformation to convert the patch into a vector representation.\n",
        "\n",
        "            Arguments: \n",
        "                patch_size: int\n",
        "                    size of the patch to cut from an image\n",
        "                d_model: int\n",
        "                    linear representation size of the patch\n",
        "                channels: int\n",
        "                    number of channels in the input image\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.channels = channels\n",
        "        self.d_model = d_model\n",
        "        self.patch_dim = channels * patch_size * patch_size\n",
        "\n",
        "        self.patch_embeddings = Rearrange(\n",
        "            'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', \n",
        "            p1 = patch_size, p2 = patch_size\n",
        "        )\n",
        "        self.embedding = nn.Linear(\n",
        "            in_features = self.patch_dim,\n",
        "            out_features = d_model\n",
        "        )\n",
        "    \n",
        "    def image_to_patches(self, img, plot_figure=False):\n",
        "        ''' Split image into patches '''\n",
        "        x = img.unsqueeze(0)\n",
        "        x = self.patch_embeddings(x)\n",
        "        batch_size, number_of_channels, PD = x.shape\n",
        "        x = x.reshape(\n",
        "            batch_size, number_of_channels, self.patch_size, self.patch_size, self.channels\n",
        "        ).squeeze(0)\n",
        "\n",
        "        if plot_figure:\n",
        "            fig = plt.figure(figsize=(8, 8))\n",
        "            matrix_shape = np.sqrt(number_of_channels).astype(int)\n",
        "            \n",
        "            for i in range(number_of_channels):\n",
        "                patch = x[i]\n",
        "                ax = fig.add_subplot(matrix_shape, matrix_shape, i+1)\n",
        "                ax.axes.get_xaxis().set_visible(False)\n",
        "                ax.axes.get_yaxis().set_visible(False)\n",
        "                ax.imshow(patch)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embeddings(x)\n",
        "        x = self.embedding(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6xba4X6J0ON"
      },
      "outputs": [],
      "source": [
        "# Refer to this links for more information about positional encoding \n",
        "# [1] https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "# [2] https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/ (code from here most likely won't work in out setting)\n",
        "# [3] https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3\n",
        "\n",
        "class PositionalEncoding(torch.nn.Module):\n",
        "    def __init__(self, d_model: int, max_seq_len: int = 256, dropout: float = 0.1):\n",
        "        '''\n",
        "          Positional encoding class, that gives the model a notion of a position of a given patch representation\n",
        "          Args:\n",
        "            d_model: int \n",
        "              Embedding dims of the model \n",
        "            max_seq_len: int \n",
        "              maximum length\n",
        "            dropout: float\n",
        "              dropout rate\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        ################\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # 1) create a positions vector\n",
        "        positions = # TODO\n",
        "\n",
        "        # 2) Calculate a division factor\n",
        "        div_factor = # TODO\n",
        "\n",
        "        # 3) Calculate a positional encoding, \n",
        "        # don't forget that sin operation is applied on each second position in the sequence\n",
        "        # ~ 3 lines\n",
        "\n",
        "        self.positional_encoding = # TODO\n",
        "\n",
        "        # 4) You can check results of your positional encoding using visualize_positional_encoding function\n",
        "        # positional_encoding tensor should be two-dimensional: time and value\n",
        "        #################\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def visualize_positional_encoding(self):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(self.positional_encoding, cmap='hot', interpolation='nearest')\n",
        "        plt.show()\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Args: \n",
        "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
        "        '''\n",
        "        x = x + self.positional_encoding[:x.shape[1]]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLkSgU4BJ0OO"
      },
      "outputs": [],
      "source": [
        "# Useful links\n",
        "# [1] https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
        "# [2] https://codeburst.io/recurrent-neural-network-4ca9fd4f242\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        ##############\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Define weights of the input tensor, hidden state tensor and bias\n",
        "        self.W_xh = # TODO\n",
        "        self.W_hh = # TODO\n",
        "        self.b = # TODO\n",
        "\n",
        "        ##############\n",
        "\n",
        "    def step_forward(self, x, state):\n",
        "        ##############\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Calculate next_state tensor of the RNN \n",
        "        next_state = # TODO\n",
        "\n",
        "        ##############\n",
        "        return next_state\n",
        "    \n",
        "    def forward(self, inputs, state=None):\n",
        "        if state is not None:\n",
        "            state = state\n",
        "        \n",
        "        B, T, _ = inputs.shape\n",
        "        outputs = torch.zeros((B, T, self.hidden_dim))\n",
        "        for idx in range(T):\n",
        "            if idx == 0:\n",
        "                outputs[:, idx, :] = self.step_forward(inputs[:, idx, :], outputs[:, 0, :])\n",
        "            else:\n",
        "                outputs[:, idx, :] = self.step_forward(inputs[:, idx, :], outputs[:, idx-1, :])\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVj1Xc3AJ0OP"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, add_bias=True):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.add_bias = add_bias\n",
        "\n",
        "        ##############\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Define weights of the input tensor and bias\n",
        "        self.W = # TODO\n",
        "        self.b = # TODO\n",
        "\n",
        "        ##############\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##############\n",
        "        \n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Define a forward calculate of the linear layer over the input tensor\n",
        "        x = # TODO\n",
        "\n",
        "        ##############\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejbfR7r7J0OP"
      },
      "outputs": [],
      "source": [
        "# Define your model here. \n",
        "# Initialize the RNN layer with hidden state dimension size \n",
        "# Initialize linear classification head. Make sure your output size matches the number of classes in the dataset\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, patch_size, embedding_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embedding = PatchEmbeddings(\n",
        "            patch_size=patch_size, d_model = embedding_dim\n",
        "        )\n",
        "        self.positional_encoding = PositionalEncoding(d_model = embedding_dim)\n",
        "\n",
        "        ###############\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        self.rnn = # TODO\n",
        "\n",
        "        self.classifier = # TODO\n",
        "\n",
        "        ###############\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        \n",
        "        ###############\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        # you forward path is here\n",
        "        logits = # TODO\n",
        "\n",
        "        ###############\n",
        "        return logits \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train loops and evaluation\n",
        "\n",
        "Here you will need to implement training and evaluation methods, as in the previous homework\n",
        "\n",
        "1) Define methods train, evaluation, and train_epoch\n",
        "\n",
        "2) Define your model instance, loss function, optimizer, and metric function\n",
        "\n",
        "3) Train model\n",
        "\n",
        "4) Evaluate model\n",
        "\n",
        "5) Do a small hyperparameter search and visualize your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaZSCHQ0J0OT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b790a4fd65b40f8948b7a4f5a168b71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114d5e5b363a4a10bdd8c6f624f0a317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2496271792f2419fa86bbb1451f4b321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3b579581cf8d424dbb5e97181a277cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e29e052a90945ed94a1a5be05d761ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b579581cf8d424dbb5e97181a277cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_114d5e5b363a4a10bdd8c6f624f0a317",
            "value": " 1183006720/? [00:11&lt;00:00, 114472949.75it/s]"
          }
        },
        "803460057842448bb386941dac2fd38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac198372fcf4d0488a2aa66a004d226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2496271792f2419fa86bbb1451f4b321",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7b766da11a74875b9c95ce4b559c50f",
            "value": 1
          }
        },
        "954e603782664638bd664b65844bb92b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b766da11a74875b9c95ce4b559c50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eeb64292f3dd4eedac9267f0fdc329d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69b49ac301f401b9e4ea65e175b7c3d",
              "IPY_MODEL_8ac198372fcf4d0488a2aa66a004d226",
              "IPY_MODEL_4e29e052a90945ed94a1a5be05d761ff"
            ],
            "layout": "IPY_MODEL_0b790a4fd65b40f8948b7a4f5a168b71"
          }
        },
        "f69b49ac301f401b9e4ea65e175b7c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_954e603782664638bd664b65844bb92b",
            "placeholder": "​",
            "style": "IPY_MODEL_803460057842448bb386941dac2fd38d",
            "value": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
